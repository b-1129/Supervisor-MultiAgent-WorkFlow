{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d8efaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Literal, List\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from IPython.display import Image, display\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "tavily_search = TavilySearchResults(max_results=2)\n",
    "\n",
    "python_repl_tool = PythonREPLTool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b1894ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervisor(BaseModel):\n",
    "    next:Literal[\"enhancer\",\"researcher\",\"coder\"] = Field(\n",
    "        description=\"Determines which specialist to activate next in the workflow sequence: \"\n",
    "                    \"'enhancer' when user input requires clarification, expansion, or refinement, \"\n",
    "                    \"'researcher' when additional facts, context, or data collection is necessary, \"\n",
    "                    \"'coder' when implementation, computation, or technical problem-solving is required.\"\n",
    "    )\n",
    "\n",
    "def supervisor_node(state:MessagesState) -> Command[Literal[\"enhancer\",\"researcher\",\"coder\"]]:\n",
    "    system_prompt = ('''\n",
    "                 \n",
    "        You are a workflow supervisor managing a team of three specialized agents: Prompt Enhancer, Researcher, and Coder. Your role is to orchestrate the workflow by selecting the most appropriate next agent based on the current state and needs of the task. Provide a clear, concise rationale for each decision to ensure transparency in your decision-making process.\n",
    "\n",
    "        **Team Members**:\n",
    "        1. **Prompt Enhancer**: Always consider this agent first. They clarify ambiguous requests, improve poorly defined queries, and ensure the task is well-structured before deeper processing begins.\n",
    "        2. **Researcher**: Specializes in information gathering, fact-finding, and collecting relevant data needed to address the user's request.\n",
    "        3. **Coder**: Focuses on technical implementation, calculations, data analysis, algorithm development, and coding solutions.\n",
    "\n",
    "        **Your Responsibilities**:\n",
    "        1. Analyze each user request and agent response for completeness, accuracy, and relevance.\n",
    "        2. Route the task to the most appropriate agent at each decision point.\n",
    "        3. Maintain workflow momentum by avoiding redundant agent assignments.\n",
    "        4. Continue the process until the user's request is fully and satisfactorily resolved.\n",
    "\n",
    "        Your objective is to create an efficient workflow that leverages each agent's strengths while minimizing unnecessary steps, ultimately delivering complete and accurate solutions to user requests.\n",
    "                 \n",
    "    ''')\n",
    "\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\": system_prompt},] + state[\"messages\"]\n",
    "    \n",
    "    response = llm.with_structured_output(Supervisor).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    print(f\" - - - Workflow Transition: Supervisor -> {goto.upper()} - - - \")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\":[\n",
    "                HumanMessage(content=reason, name=\"supervisor\")\n",
    "            ]\n",
    "        },\n",
    "        goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77222b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhancer_node(state:MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    \"\"\"\n",
    "    Enhancer agent node that improves and clarify users queries.\n",
    "    Takes the original user input and transforms it into a more precise,\n",
    "    actionable request before passing it to the supervisor.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "        \"You are a Query Refinement Specialist with expertise in transforming vague requests into precise instructions. Your responsibilities include:\\n\\n\"\n",
    "        \"1. Analyzing the original query to identify key intent and requirements\\n\"\n",
    "        \"2. Resolving any ambiguities without requesting additional user input\\n\"\n",
    "        \"3. Expanding underdeveloped aspects of the query with reasonable assumptions\\n\"\n",
    "        \"4. Restructuring the query for clarity and actionability\\n\"\n",
    "        \"5. Ensuring all technical terminology is properly defined in context\\n\\n\"\n",
    "        \"Important: Never ask questions back to the user. Instead, make informed assumptions and create the most comprehensive version of their request possible.\"\n",
    "\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":system_prompt},\n",
    "    ]+ state[\"messages\"]\n",
    "\n",
    "    enhanced_query = llm.invoke(messages)\n",
    "\n",
    "    print(f\"- - - Workflow Transition: Prompt Enhancer -> Supervisor - - - \")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\":[HumanMessage(content=enhanced_query.content, name=\"enhancer\")]\n",
    "        }, goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "823da9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state:MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "    \"\"\"\n",
    "    Reseacrh agent node that gathers information using Tavily search.\n",
    "    Take the current task state, performs relevant research,\n",
    "    and returns findings for validation.\n",
    "    \"\"\"\n",
    "    research_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[tavily_search],\n",
    "        state_modifier = \"You are an Information Specialist with expertise in comprehensive research. Your responsibilities include:\\n\\n\"\n",
    "            \"1. Identifying key information needs based on the query context\\n\"\n",
    "            \"2. Gathering relevant, accurate, and up-to-date information from reliable sources\\n\"\n",
    "            \"3. Organizing findings in a structured, easily digestible format\\n\"\n",
    "            \"4. Citing sources when possible to establish credibility\\n\"\n",
    "            \"5. Focusing exclusively on information gathering - avoid analysis or implementation\\n\\n\"\n",
    "            \"Provide thorough, factual responses without speculation where information is unavailable.\"\n",
    "    )\n",
    "    result = research_agent.invoke(state)\n",
    "\n",
    "    print(f\"- - - Workflow Transition: Research -> Validator - - -\")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\":[HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")]\n",
    "        },goto=\"validator\",\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ad34c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_node(state:MessagesState) -> Command[Literal[\"validator\"]]:\n",
    "    code_agent = create_react_agent(\n",
    "        llm,\n",
    "        tools=[python_repl_tool],\n",
    "        state_modifier=(\n",
    "            \"You are a coder and analyst. Focus on mathematical calculations, analyzing, solving math questions,\"\n",
    "            \"and executing code. Handle technical problem-solving and data tasks.\"\n",
    "        )\n",
    "    )\n",
    "    result = code_agent.invoke(state)\n",
    "\n",
    "    print(f\"- - - Workflow transition: Coder -> validator - - - \")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\":[HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")]\n",
    "        }, goto=\"validator\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d5b5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt providing clear instructions to the validator agent\n",
    "system_prompt = '''\n",
    "    Your task is to ensure reasonable quality. \n",
    "    Specifically, you must:\n",
    "    - Review the user's question (the first message in the workflow).\n",
    "    - Review the answer (the last message in the workflow).\n",
    "    - If the answer addresses the core intent of the question, even if not perfectly, signal to end the workflow with 'FINISH'.\n",
    "    - Only route back to the supervisor if the answer is completely off-topic, harmful, or fundamentally misunderstands the question.\n",
    "    \n",
    "    - Accept answers that are \"good enough\" rather than perfect\n",
    "    - Prioritize workflow completion over perfect responses\n",
    "    - Give benefit of doubt to borderline answers\n",
    "    \n",
    "    Routing Guidelines:\n",
    "    1. 'supervisor' Agent: ONLY for responses that are completely incorrect or off-topic.\n",
    "    2. Respond with 'FINISH' in all other cases to end the workflow.\n",
    "'''\n",
    "\n",
    "class Validator(BaseModel):\n",
    "    next: Literal[\"supervisor\", \"FINISH\"] = Field(\n",
    "        description=\"Specifies the next worker in the pipeline: 'supervisor' to continue or 'FINISH' to terminate.\"\n",
    "    )\n",
    "    reason:str = Field(\n",
    "        description=\"The reason for the decision.\"\n",
    "    )\n",
    "\n",
    "def validator_node(state:MessagesState) -> Command[Literal[\"supervisor\", \"__end__\"]]:\n",
    "    user_question = state[\"messages\"][0].content\n",
    "    agent_answer = state[\"messages\"][-1].content\n",
    "\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":system_prompt},\n",
    "        {\"role\":\"user\", \"content\":user_question},\n",
    "        {\"role\":\"assistant\", \"content\":agent_answer},\n",
    "    ]\n",
    "\n",
    "    response = llm.with_structured_output(Validator).invoke(messages)\n",
    "\n",
    "    goto = response.next\n",
    "    reason = response.reason\n",
    "\n",
    "    if goto == \"FINISH\" or goto == END:\n",
    "        goto = END\n",
    "        print(\"- - - Transitioning to END\")\n",
    "    else:\n",
    "        print(f\"- - - Workflow Transition: validato -> supervisor - - - \")\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\":[HumanMessage(content=reason,name=\"validator\")]\n",
    "        }, goto=goto,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4c6533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"enhancer\", enhancer_node)\n",
    "graph.add_node(\"researcher\", research_node)\n",
    "graph.add_node(\"coder\",code_node)\n",
    "graph.add_node(\"validator\",validator_node)\n",
    "\n",
    "graph.add_edge(START, \"supervisor\")\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c20a7d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f9b501c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpprint\u001b[39;00m\n\u001b[32m      3\u001b[39m inputs = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      5\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mweather in surat\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     ]\n\u001b[32m      7\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2461\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2455\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2456\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2458\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2459\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2460\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2468\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\pregel\\runner.py:153\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    151\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36msupervisor_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     10\u001b[39m system_prompt = (\u001b[33m'''\u001b[39m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[33m    You are a workflow supervisor managing a team of three specialized agents: Prompt Enhancer, Researcher, and Coder. Your role is to orchestrate the workflow by selecting the most appropriate next agent based on the current state and needs of the task. Provide a clear, concise rationale for each decision to ensure transparency in your decision-making process.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \n\u001b[32m     27\u001b[39m \u001b[33m\u001b[39m\u001b[33m'''\u001b[39m)\n\u001b[32m     29\u001b[39m messages = [\n\u001b[32m     30\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: system_prompt},] + state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSupervisor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m goto = response.next\n\u001b[32m     35\u001b[39m reason = response.reason\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3032\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3030\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3031\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3032\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3033\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3034\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5409\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5411\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5414\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5415\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:370\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m     **kwargs: Any,\n\u001b[32m    366\u001b[39m ) -> BaseMessage:\n\u001b[32m    367\u001b[39m     config = ensure_config(config)\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    369\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    380\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:947\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    940\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     **kwargs: Any,\n\u001b[32m    945\u001b[39m ) -> LLMResult:\n\u001b[32m    946\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:766\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    765\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m         )\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    774\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1012\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1016\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:935\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    933\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    937\u001b[39m     _handle_openai_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:158\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    153\u001b[39m         response_format=response_format,\n\u001b[32m    154\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    155\u001b[39m         input_tools=tools,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "During task with name 'supervisor' and id '515652f4-2bf1-b502-a5f2-ca704f393c3f'"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"weather in surat\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        last_message = value.get(\"messages\",[])[-1] if \"messages\" in value else None\n",
    "        if last_message:\n",
    "            pprint.pprint(f\"output from node '{key}':\")\n",
    "            pprint.pprint(last_message, indent=2, width=80, depth=None)\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5db300a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpprint\u001b[39;00m\n\u001b[32m      3\u001b[39m inputs = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m:[\n\u001b[32m      5\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mGive me the 20th fibonacci number.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      6\u001b[39m     ]\n\u001b[32m      7\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2461\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2455\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2456\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2458\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2459\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2460\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2468\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\pregel\\runner.py:153\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    151\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36msupervisor_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     10\u001b[39m system_prompt = (\u001b[33m'''\u001b[39m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[33m    You are a workflow supervisor managing a team of three specialized agents: Prompt Enhancer, Researcher, and Coder. Your role is to orchestrate the workflow by selecting the most appropriate next agent based on the current state and needs of the task. Provide a clear, concise rationale for each decision to ensure transparency in your decision-making process.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \n\u001b[32m     27\u001b[39m \u001b[33m\u001b[39m\u001b[33m'''\u001b[39m)\n\u001b[32m     29\u001b[39m messages = [\n\u001b[32m     30\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: system_prompt},] + state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSupervisor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m goto = response.next\n\u001b[32m     35\u001b[39m reason = response.reason\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3032\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3030\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3031\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3032\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3033\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3034\u001b[39m         \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5409\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5411\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5414\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5415\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:370\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m     **kwargs: Any,\n\u001b[32m    366\u001b[39m ) -> BaseMessage:\n\u001b[32m    367\u001b[39m     config = ensure_config(config)\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    369\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    380\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:947\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    940\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     **kwargs: Any,\n\u001b[32m    945\u001b[39m ) -> LLMResult:\n\u001b[32m    946\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:766\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    765\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m         )\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    774\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1012\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1016\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:935\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    933\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    937\u001b[39m     _handle_openai_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:158\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    153\u001b[39m         response_format=response_format,\n\u001b[32m    154\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    155\u001b[39m         input_tools=tools,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\langgraph learning\\langgraph\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "During task with name 'supervisor' and id 'd624b5ac-636f-0ff6-8040-1bf113a1553a'"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"messages\":[\n",
    "        (\"user\",\"Give me the 20th fibonacci number.\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "for event in app.stream(inputs):\n",
    "    for key, value in event.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        pprint.pprint(f\"output from node: '{key}'\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87275906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
